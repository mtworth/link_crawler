{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNENupUo92KFpvSvKEJhn29"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zgNAJNhKbcDI"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import pandas as pd\n",
        "\n",
        "def extract_links(url, visited):\n",
        "    \"\"\"\n",
        "    Extract all unique links from the given URL that have not been visited.\n",
        "    \"\"\"\n",
        "    links = set()\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for anchor in soup.find_all('a', href=True):\n",
        "            href = anchor['href']\n",
        "            full_url = urljoin(url, href)\n",
        "            if urlparse(full_url).scheme in ['http', 'https'] and full_url not in visited:\n",
        "                links.add(full_url)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting links from {url}: {e}\")\n",
        "    return links\n",
        "\n",
        "def get_domain(url):\n",
        "    \"\"\"\n",
        "    Extract the domain name from a URL.\n",
        "    \"\"\"\n",
        "    parsed_url = urlparse(url)\n",
        "    return parsed_url.netloc\n",
        "\n",
        "def crawl_website(start_url, max_depth):\n",
        "    \"\"\"\n",
        "    Crawl a website starting from `start_url` and explore up to `max_depth` layers deep.\n",
        "    \"\"\"\n",
        "    visited = set()\n",
        "    todo = set([start_url])\n",
        "    unique_links = set()\n",
        "    level = 0\n",
        "\n",
        "    while level < max_depth and todo:\n",
        "        new_todo = set()\n",
        "        for url in list(todo):\n",
        "            if url not in visited:\n",
        "                visited.add(url)\n",
        "                print(f\"Processing Level {level+1}/{max_depth}, URL: {url}\")\n",
        "                sublinks = extract_links(url, visited)\n",
        "                unique_links.update(sublinks)\n",
        "                new_todo.update(sublinks)\n",
        "        todo = new_todo\n",
        "        level += 1\n",
        "\n",
        "    # Convert unique links to a DataFrame with two columns: 'Link' and 'Domain'\n",
        "    data = {'Link': list(unique_links), 'Domain': [get_domain(link) for link in unique_links]}\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "start_url = 'https://governmentassistanceonline.com/'\n",
        "max_depth = 2\n",
        "df = crawl_website(start_url, max_depth)\n",
        "print(\"\\nFinal Links table:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5FI-_opdSI8",
        "outputId": "7d76a3b2-280a-4e63-db50-0d1f593132b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Level 1/2, URL: https://governmentassistanceonline.com/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/privacy/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/about-us\n",
            "Processing Level 2/2, URL: https://opgcustomerprivacy.com/contact-us/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/#content\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com\n",
            "Processing Level 2/2, URL: https://opgcustomerprivacy.com/marketing-partners/\n",
            "Processing Level 2/2, URL: https://opgguides.com/faqs/general/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/programs/\n",
            "Processing Level 2/2, URL: https://opgcustomerprivacy.com/do-not-sell-my-information/\n",
            "Processing Level 2/2, URL: https://opgcustomerprivacy.com/california-privacy-request/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/guides/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/unsubscribe/?refSite=governmentassistanceonline.com\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/about-us/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/medicaid/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/cookies/\n",
            "Processing Level 2/2, URL: https://opgcustomerprivacy.com/website-partners/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/tc/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/posts/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/fha/\n",
            "Processing Level 2/2, URL: https://governmentassistanceonline.com/rent-to-own-homes/\n",
            "\n",
            "Final Links table:\n",
            "                                                   Link  \\\n",
            "0              https://opgguides.com/category/seniors/   \n",
            "1    https://opgguides.com/faqs/unemployment-benefits/   \n",
            "2              https://opgguides.com/faqs/rent-to-own/   \n",
            "3       https://governmentassistanceonline.com/grants/   \n",
            "4           https://opgcustomerprivacy.com/contact-us/   \n",
            "..                                                 ...   \n",
            "114            https://opgcustomerprivacy.com/privacy/   \n",
            "115                    https://opgcustomerprivacy.com/   \n",
            "116  https://governmentassistanceonline.com/posts/p...   \n",
            "117  https://governmentassistanceonline.com/food-st...   \n",
            "118       https://opgguides.com/faqs/health-insurance/   \n",
            "\n",
            "                             Domain  \n",
            "0                     opgguides.com  \n",
            "1                     opgguides.com  \n",
            "2                     opgguides.com  \n",
            "3    governmentassistanceonline.com  \n",
            "4            opgcustomerprivacy.com  \n",
            "..                              ...  \n",
            "114          opgcustomerprivacy.com  \n",
            "115          opgcustomerprivacy.com  \n",
            "116  governmentassistanceonline.com  \n",
            "117  governmentassistanceonline.com  \n",
            "118                   opgguides.com  \n",
            "\n",
            "[119 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Domain'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69oRSV2vdecR",
        "outputId": "5ef06074-8243-441d-db64-0a88701cbf1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['opgguides.com', 'governmentassistanceonline.com',\n",
              "       'opgcustomerprivacy.com'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}